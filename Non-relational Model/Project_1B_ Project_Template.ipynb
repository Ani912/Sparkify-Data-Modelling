{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import json\n",
    "import cassandra\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Dir - /home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(f\"Current Dir - {os.getcwd()}\")\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.path.join(os.getcwd(), 'event_data')\n",
    "\n",
    "# Create a glob listing all the CSVs from filepath\n",
    "file_path_list = glob.glob(os.path.join(filepath,'*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "        # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "from cassandra.cluster import Cluster\n",
    "try:\n",
    "    # To establish connection and begin executing queries, need a session\n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Keyspace details\n",
    "keyspace_name = 'sparkify'\n",
    "replication_strat = {'class' : 'SimpleStrategy', 'replication_factor' : 1 }\n",
    "create_keyspc = \"\"\"CREATE KEYSPACE IF NOT EXISTS {0} WITH REPLICATION = {1}\"\"\".format(keyspace_name, replication_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating a Keyspace \n",
    "try:\n",
    "    session.execute(create_keyspc)\n",
    "except Exception as e:\n",
    "    raise Exception(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace(keyspace_name)\n",
    "except Exception as e:\n",
    "    raise Exception(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 1:\n",
    "> The artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4\n",
    "\n",
    "\n",
    "Query for the data would look like:\n",
    "```\n",
    "select \n",
    "    artist, \n",
    "    song_title, \n",
    "    song_length \n",
    "from \n",
    "    session_songs \n",
    "where \n",
    "    sessionId = 338 \n",
    "    and itemInSession = 4\n",
    "```\n",
    "\n",
    "Plan:\n",
    "1. As can be seen we require sessionId and itemInSession in our where clause so we know what both those are gonna make our composite primary key.\n",
    "2. sessionId would be the partition key and itemInSession would be clustering key. Mainly because sessionId would be unique for every session.\n",
    "3. Now that we know our primary keys we will also need artist name, song name and song length to satisfy the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "create_query1 = \"\"\"CREATE TABLE IF NOT EXISTS session_songs\n",
    "(sessionId int, itemInSession int, artist text, song_title text, song_length float,\n",
    "PRIMARY KEY(sessionId, itemInSession))\"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(create_query1)\n",
    "except Exception as e:\n",
    "    raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO session_songs (sessionId, itemInSession, artist, song_title, song_length)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        artist_name, user_name, gender, itemInSession, user_last_name, length, level, location, sessionId, song, userId = line\n",
    "        # wrapping casts to bypass python data defs and feed data to cassandra\n",
    "        try:\n",
    "            session.execute(query, (int(sessionId), int(itemInSession), artist_name, song, float(length)))\n",
    "        except Exception as e:\n",
    "            raise Exception(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query output - \n",
      "Faithless Music Matters (Mark Knight Dub) 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "val_query1 = \"\"\"select artist, song_title, song_length from session_songs where sessionId = 338 and itemInSession = 4\"\"\"\n",
    "try:\n",
    "    rows = session.execute(val_query1)\n",
    "except Exception as e:\n",
    "    raise Exception(e)\n",
    "\n",
    "print(\"Query output - \")\n",
    "for row in rows:\n",
    "    print(row.artist, row.song_title, row.song_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 2:\n",
    "> Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "\n",
    "Query for the data would look like:\n",
    "```\n",
    "select \n",
    "    temInSession, \n",
    "    artist, \n",
    "    song, \n",
    "    firstName, \n",
    "    lastName \n",
    "from \n",
    "    user_songs \n",
    "where \n",
    "    userId = 10 \n",
    "    and sessionId = 182\n",
    "```\n",
    "\n",
    "Plan:\n",
    "1. As can be seen we require sessionId and userId in our where clause so we know that both those together are gonna make our partition key. Main reason for this would be the fact that multiple user can have the same sessionId, combined together it should give us a unique partition key.\n",
    "2. Also now that we our results sorted by itemInSession this would have to be our clustering key. \n",
    "3. So altogether our primary key should be ((userId, sessionId), itemInSession)\n",
    "4. The only thing now left is to determine the other columns we require to fulfill the query above which would be temInSession, artist, song, firstName, lastName "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "create_query2 = \"\"\"CREATE TABLE IF NOT EXISTS user_songs\n",
    "(userId int, sessionId int, artist text, song text, firstName text, lastName text, itemInSession int,\n",
    "PRIMARY KEY((userId, sessionId), itemInSession))\"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(create_query2)\n",
    "except Exception as e:\n",
    "    raise Exception(e)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_songs (userId, sessionId, artist, song, firstName, lastName, itemInSession)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        artist, firstName, gender, itemInSession, lastName, length, level, location, sessionId, song, userId = line\n",
    "        # wrapping casts to bypass python data defs and feed data to cassandra\n",
    "        try:\n",
    "            session.execute(query, (int(userId), int(sessionId), artist, song, firstName, lastName, int(itemInSession)))\n",
    "        except Exception as e:\n",
    "            raise Exception(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query output - \n",
      "0 Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "1 Three Drives Greece 2000 Sylvie Cruz\n",
      "2 Sebastien Tellier Kilometer Sylvie Cruz\n",
      "3 Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "val_query2 = \"\"\"select itemInSession, artist, song, firstName, lastName from user_songs where userId = 10 and sessionId = 182\"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(val_query2)\n",
    "except Exception as e:\n",
    "    raise Exception(e)\n",
    "\n",
    "print(\"Query output - \")\n",
    "for row in rows:\n",
    "    print(row.iteminsession, row.artist, row.song, row.firstname, row.lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 3:\n",
    "> Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n",
    "Query for the data would look like:\n",
    "```\n",
    "select \n",
    "    firstName, \n",
    "    lastName \n",
    "from \n",
    "    app_history \n",
    "where \n",
    "    song = 'All Hands Against His Own'\n",
    "```\n",
    "\n",
    "Plan:\n",
    "1. This is a unique case where we have only song as where clause, so I think it'd be best to make a primary key out of song and userId to make sure we have it unique across the data. Because user name wouldn't warrant a unique behavior.\n",
    "2. Besides that we need the user name - (first name, last name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "create_query3 = \"\"\"CREATE TABLE IF NOT EXISTS app_history\n",
    "(song text, firstName text, lastName text, userId int,\n",
    "PRIMARY KEY(song, userId))\"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(create_query3)\n",
    "except Exception as e:\n",
    "    raise Exception(e)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO app_history (song, firstName, lastName, userId)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "        artist, firstName, gender, itemInSession, lastName, length, level, location, sessionId, song, userId = line\n",
    "        # wrapping casts to bypass python data defs and feed data to cassandra\n",
    "        try:\n",
    "            session.execute(query, (song, firstName, lastName, int(userId)))\n",
    "        except Exception as e:\n",
    "            raise Exception(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query output - \n",
      "1 Jacqueline Lynch\n",
      "2 Tegan Levine\n",
      "3 Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "val_query3 = \"\"\"select firstName, lastName from app_history where song = 'All Hands Against His Own'\"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(val_query3)\n",
    "except Exception as e:\n",
    "    raise Exception(e)\n",
    "\n",
    "print(\"Query output - \")\n",
    "for i, row in enumerate(rows):\n",
    "    print(i+1, row.firstname, row.lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "drop_query1 = \"drop table session_songs\"\n",
    "drop_query2 = \"drop table user_songs\"\n",
    "drop_query3 = \"drop table app_history\"\n",
    "try:\n",
    "    val1 = session.execute(drop_query1)\n",
    "    val2 = session.execute(drop_query2)\n",
    "    val3 = session.execute(drop_query3)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
